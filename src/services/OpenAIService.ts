import OpenAI from 'openai';
import path from 'path';
import dotenv from 'dotenv';
import { CircuitBreakerService } from './CircuitBreakerService';
import logger from '../utils/Logger';

dotenv.config({ path: path.resolve(__dirname, '../.env') });


export interface AIResponse {
  success: boolean;
  response?: string;
  error?: string;
  blocked?: boolean;
  reason?: string;
  timeRemaining?: number;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface MessageContext {
  sessionId: string;
  messageId: string;
  fromUser: string;
  content: string;
  messageType: string;
  timestamp: Date;
  conversationHistory?: Array<{
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date;
  }>;
}

export class OpenAIService {
  private client: OpenAI;
  private isEnabled: boolean = true;
  private model: string = 'gpt-4o-mini';
  private maxTokens: number = 500;
  private temperature: number = 0.7;
  private circuitBreaker: CircuitBreakerService;
  private systemPrompt: string = `Voc√™ √© uma atendente de farm√°cia virtual, com profundo conhecimento de medicamentos, gen√©ricos, similares e contra-indica√ß√µes. Ao receber perguntas de clientes, siga essas diretrizes:

1. **Identifica√ß√£o do medicamento:** Apresente nome gen√©rico, nomes comerciais e dosagens dispon√≠veis.
2. **Verifica√ß√£o de indica√ß√µes e contraindica√ß√µes:** Descreva para quais condi√ß√µes √© indicado, principais efeitos colaterais e intera√ß√µes.
3. **Pesquisa de pre√ßos:** Realize uma busca r√°pida na web (utilizando fontes confi√°veis) para encontrar o menor pre√ßo de cada apresenta√ß√£o (farm√°cia f√≠sica ou online).
4. **Exibi√ß√£o de imagem:** Providencie o link ou uma miniatura da embalagem do medicamento, se dispon√≠vel.
5. **Tom profissional e acolhedor:** Responda com clareza, evitando termos t√©cnicos demais, mas mantendo precis√£o.
6. **Formato da resposta:**
   - **Nome completo do produto:** 
   - **Dosagem e apresenta√ß√£o:** 
   - **Indica√ß√µes / Contraindica√ß√µes:** 
   - **Pre√ßo mais baixo encontrado:** (informe estabelecimento e valor)
   - **Imagem:** (link ou embed)

Suas caracter√≠sticas:
- Sempre seja cordial e profissional
- Responda de forma clara e objetiva sobre medicamentos e produtos farmac√™uticos
- Seja √∫til e prestativo com d√∫vidas sobre pre√ßos, disponibilidade e informa√ß√µes de medicamentos
- Mantenha um tom amig√°vel e acolhedor
- Se n√£o souber algo espec√≠fico sobre um medicamento, seja honesto e sugira consultar um farmac√™utico
- Use emojis ocasionalmente para tornar a conversa mais amig√°vel
- Foque em informa√ß√µes sobre produtos farmac√™uticos, pre√ßos e disponibilidade

Contexto: Voc√™ est√° atendendo clientes via WhatsApp para uma farm√°cia. As mensagens que chegam at√© voc√™ j√° foram filtradas por palavras-chave relacionadas a d√∫vidas farmac√™uticas (d√∫vida, pharma, rem√©dio, pre√ßo).`;

  constructor() {
    const apiKey = process.env.OPENAI_API_KEY;
    
    if (apiKey) {
      this.client = new OpenAI({
        apiKey: apiKey,
      });
      this.isEnabled = true;
      
      // Circuit Breaker para OpenAI - 3 falhas, 60s de cooldown
      this.circuitBreaker = CircuitBreakerService.getInstance('OpenAI', 3, 60000);
      logger.info('ü§ñ OpenAI Service inicializado com sucesso');
    } else {
      logger.warn('‚ö†Ô∏è OPENAI_API_KEY n√£o configurada. OpenAI Service desabilitado.');
      this.isEnabled = false;
    }
  }

  /**
   * Processa uma mensagem e gera uma resposta usando IA
   */
  async processMessage(context: MessageContext): Promise<AIResponse> {
    try {
      if (!this.isEnabled) {
        return {
          success: false,
          error: 'OpenAI Service n√£o est√° habilitado. Configure OPENAI_API_KEY.'
        };
      }

      logger.info(`ü§ñ Processando mensagem com IA: ${context.messageId}`);

      // Preparar hist√≥rico da conversa
      const messages = this.prepareConversationHistory(context);

      // Fazer chamada para a OpenAI
      const completion = await this.circuitBreaker.execute(() =>
        this.client.chat.completions.create({
          model: this.model,
          messages: messages,
          max_tokens: this.maxTokens,
          temperature: this.temperature,
        })
      );

      const response = completion.choices[0]?.message?.content;

      if (!response) {
        return {
          success: false,
          error: 'N√£o foi poss√≠vel gerar uma resposta da IA'
        };
      }

      logger.info(`‚úÖ Resposta da IA gerada: ${response.substring(0, 100)}...`);

      return {
        success: true,
        response: response,
        usage: {
          prompt_tokens: completion.usage?.prompt_tokens || 0,
          completion_tokens: completion.usage?.completion_tokens || 0,
          total_tokens: completion.usage?.total_tokens || 0,
        }
      };

    } catch (error: any) {
      logger.error('üî¥ Erro ao processar mensagem com IA:', error);
      
      return {
        success: false,
        error: error.message || 'Erro desconhecido ao processar com IA'
      };
    }
  }

  /**
   * Prepara o hist√≥rico da conversa para enviar √† OpenAI
   */
  private prepareConversationHistory(context: MessageContext): Array<{ role: 'system' | 'user' | 'assistant'; content: string }> {
    const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      {
        role: 'system',
        content: this.systemPrompt
      }
    ];

    // Adicionar hist√≥rico da conversa se dispon√≠vel
    if (context.conversationHistory && context.conversationHistory.length > 0) {
      // Pegar apenas as √∫ltimas 10 mensagens para n√£o exceder limites
      const recentHistory = context.conversationHistory.slice(-10);
      
      for (const msg of recentHistory) {
        messages.push({
          role: msg.role,
          content: msg.content
        });
      }
    }

    // Adicionar a mensagem atual
    messages.push({
      role: 'user',
      content: context.content
    });

    return messages;
  }

  /**
   * Verifica se o servi√ßo est√° habilitado
   */
  isServiceEnabled(): boolean {
    return this.isEnabled;
  }

  /**
   * Atualiza a configura√ß√£o do sistema
   */
  updateConfiguration(config: {
    model?: string;
    maxTokens?: number;
    temperature?: number;
    systemPrompt?: string;
  }): void {
    if (config.model) this.model = config.model;
    if (config.maxTokens) this.maxTokens = config.maxTokens;
    if (config.temperature) this.temperature = config.temperature;
    if (config.systemPrompt) this.systemPrompt = config.systemPrompt;

    logger.info('‚öôÔ∏è Configura√ß√£o da OpenAI atualizada:', config);
  }

  /**
   * Obt√©m estat√≠sticas do servi√ßo
   */
  getStats(): any {
    return {
      enabled: this.isEnabled,
      model: this.model,
      maxTokens: this.maxTokens,
      temperature: this.temperature,
      systemPrompt: this.systemPrompt.substring(0, 100) + '...'
    };
  }

  /**
   * Testa a conex√£o com a OpenAI
   */
  async testConnection(): Promise<{ success: boolean; error?: string }> {
    try {
      if (!this.isEnabled) {
        return { success: false, error: 'Servi√ßo n√£o habilitado' };
      }

      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: [{ role: 'user', content: 'Teste de conex√£o' }],
        max_tokens: 10,
      });

      return { success: true };
    } catch (error: any) {
      return { success: false, error: error.message };
    }
  }
} 